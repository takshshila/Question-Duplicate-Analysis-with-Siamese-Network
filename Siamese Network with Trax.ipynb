{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network\n",
    "<img src = 'images/Siamese_Network_Architecture.png' width=\"width\" height=\"height\" style=\"height:250px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takshshilarawat/opt/anaconda3/lib/python3.7/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n",
    "import trax.fastmath.numpy as np\n",
    "import numpy\n",
    "\n",
    "# Setting random seeds\n",
    "trax.supervised.trainer_lib.init_random_number_generators(10)\n",
    "numpy.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return x / np.sqrt(np.sum(x * x, axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "model_dimension = 128\n",
    "\n",
    "# Define the LSTM model\n",
    "LSTM = tl.Serial(\n",
    "        tl.Embedding(vocab_size=vocab_size, d_feature=model_dimension),\n",
    "        tl.LSTM(model_dimension),\n",
    "        tl.Mean(axis=1),\n",
    "        tl.Fn('Normalize', lambda x: normalize(x))\n",
    "    )\n",
    "\n",
    "# Use the Parallel combinator to create a Siamese model out of the LSTM \n",
    "Siamese = tl.Parallel(LSTM, LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese model:\n",
      "\n",
      "Total layers: 2\n",
      "\n",
      "========\n",
      "Parallel.sublayers_0: Serial[\n",
      "  Embedding_500_128\n",
      "  LSTM_128\n",
      "  Mean\n",
      "  Normalize\n",
      "]\n",
      "\n",
      "========\n",
      "Parallel.sublayers_1: Serial[\n",
      "  Embedding_500_128\n",
      "  LSTM_128\n",
      "  Mean\n",
      "  Normalize\n",
      "]\n",
      "\n",
      "Detail of LSTM models:\n",
      "\n",
      "Total layers: 4\n",
      "\n",
      "========\n",
      "Serial.sublayers_0: Embedding_500_128\n",
      "\n",
      "========\n",
      "Serial.sublayers_1: LSTM_128\n",
      "\n",
      "========\n",
      "Serial.sublayers_2: Mean\n",
      "\n",
      "========\n",
      "Serial.sublayers_3: Normalize\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_layers(model, layer_prefix):\n",
    "    print(f\"Total layers: {len(model.sublayers)}\\n\")\n",
    "    for i in range(len(model.sublayers)):\n",
    "        print('========')\n",
    "        print(f'{layer_prefix}_{i}: {model.sublayers[i]}\\n')\n",
    "\n",
    "print('Siamese model:\\n')\n",
    "show_layers(Siamese, 'Parallel.sublayers')\n",
    "\n",
    "print('Detail of LSTM models:\\n')\n",
    "show_layers(LSTM, 'Serial.sublayers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate a Siamese model\n",
    "\n",
    "## Inspecting the necessary elements\n",
    "\n",
    " - `q1`: vector with dimension `(batch_size X max_length)` containing first questions to compare in the test set.\n",
    " - `q2`: vector with dimension `(batch_size X max_length)` containing second questions to compare in the test set.\n",
    "   \n",
    "   **Notice that for each pair of vectors within a batch $([q1_1, q1_2, q1_3, ...]$, $[q2_1, q2_2,q2_3, ...])$  $q1_i$ is associated to $q2_k$.**\n",
    "        \n",
    "        \n",
    "   - `y_test`: 1 if  $q1_i$ and $q2_k$ are duplicates, 0 otherwise.\n",
    "   \n",
    "   - `v1`: output vector from the model's prediction associated with the first questions.\n",
    "   - `v2`: output vector from the model's prediction associated with the second questions.\n",
    "   \n",
    "   \n",
    "   **The value of `1` was used for padding.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 has shape: (512, 64) \n",
      "\n",
      "And it looks like this: \n",
      "\n",
      " [[ 32  38   4 ...   1   1   1]\n",
      " [ 30 156  78 ...   1   1   1]\n",
      " [ 32  38   4 ...   1   1   1]\n",
      " ...\n",
      " [ 32  33   4 ...   1   1   1]\n",
      " [ 30 156 317 ...   1   1   1]\n",
      " [ 30 156   6 ...   1   1   1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1 = np.load('data/q1.npy')\n",
    "print(f'q1 has shape: {q1.shape} \\n\\nAnd it looks like this: \\n\\n {q1}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q2 has shape: (512, 64) \n",
      "\n",
      "And looks like this: \n",
      "\n",
      " [[   30   156    78 ...     1     1     1]\n",
      " [  283   156    78 ...     1     1     1]\n",
      " [   32    38     4 ...     1     1     1]\n",
      " ...\n",
      " [   32    33     4 ...     1     1     1]\n",
      " [   30   156    78 ...     1     1     1]\n",
      " [   30   156 10596 ...     1     1     1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2 = np.load('data/q2.npy')\n",
    "print(f'q2 has shape: {q2.shape} \\n\\nAnd looks like this: \\n\\n {q2}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test has shape: (512,) \n",
      "\n",
      "And looks like this: \n",
      "\n",
      " [0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1\n",
      " 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1\n",
      " 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = np.load('data/y_test.npy')\n",
    "print(f'y_test has shape: {y_test.shape} \\n\\nAnd looks like this: \\n\\n {y_test}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 has shape: (512, 128) \n",
      "\n",
      "And looks like this: \n",
      "\n",
      " [[ 0.01273625 -0.1496373  -0.01982759 ...  0.02205012 -0.00169148\n",
      "  -0.01598107]\n",
      " [-0.05592084  0.05792497 -0.02226785 ...  0.08156938 -0.02570007\n",
      "  -0.00503111]\n",
      " [ 0.05686752  0.0294889   0.04522024 ...  0.03141788 -0.08459651\n",
      "  -0.00968536]\n",
      " ...\n",
      " [ 0.15115018  0.17791134  0.02200656 ... -0.00851707  0.00571415\n",
      "  -0.00431194]\n",
      " [ 0.06995274  0.13110274  0.0202337  ... -0.00902792 -0.01221745\n",
      "   0.00505962]\n",
      " [-0.16043712 -0.11899089 -0.15950686 ...  0.06544471 -0.01208312\n",
      "  -0.01183368]]\n",
      "\n",
      "\n",
      "v2 has shape: (512, 128) \n",
      "\n",
      "And looks like this: \n",
      "\n",
      " [[ 0.07437647  0.02804951 -0.02974014 ...  0.02378932 -0.01696189\n",
      "  -0.01897198]\n",
      " [ 0.03270066  0.15122835 -0.02175895 ...  0.00517202 -0.14617395\n",
      "   0.00204823]\n",
      " [ 0.05635608  0.05454165  0.042222   ...  0.03831453 -0.05387777\n",
      "  -0.01447786]\n",
      " ...\n",
      " [ 0.04727105 -0.06748016  0.04194937 ...  0.07600753 -0.03072828\n",
      "   0.00400715]\n",
      " [ 0.00269269  0.15222628  0.01714724 ...  0.01482705 -0.0197884\n",
      "   0.01389528]\n",
      " [-0.15475044 -0.15718803 -0.14732707 ...  0.04299919 -0.01070975\n",
      "  -0.01318042]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v1 = np.load('data/v1.npy')\n",
    "print(f'v1 has shape: {v1.shape} \\n\\nAnd looks like this: \\n\\n {v1}\\n\\n')\n",
    "v2 = np.load('data/v2.npy')\n",
    "print(f'v2 has shape: {v2.shape} \\n\\nAnd looks like this: \\n\\n {v2}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the accuracy\n",
    "\n",
    "**Note :A higher threshold means that only very similar questions will be considered as the same question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512 # Note: The max it can be is y_test.shape[0] i.e all the samples in test data\n",
    "threshold = 0.7 # You can play around with threshold and then see the change in accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Be careful with the indices when slicing the test data in the assignment!**\n",
    "\n",
    "The process is pretty straightforward:\n",
    "   - Iterate over each one of the elements in the batch\n",
    "   - Compute the cosine similarity between the predictions\n",
    "       - For computing the cosine similarity, the two output vectors should have been normalized using L2 normalization meaning their magnitude will be 1. This has been taken care off by the Siamese network you will build in the assignment. Hence the cosine similarity here is just dot product between two vectors. You can check by implementing the usual cosine similarity formula and check if this holds or not.\n",
    "   - Determine if this value is greater than the threshold (If it is, consider the two questions as the same and return 1 else 0)\n",
    "   - Compare against the actual target and if the prediction matches, add 1 to the accuracy (increment the correct prediction counter)\n",
    "   - Divide the accuracy by the number of processed elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
